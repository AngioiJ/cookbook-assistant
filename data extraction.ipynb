{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Text Extraction from the Cookbook PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import re\n",
    "from rapidfuzz import fuzz, process\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examing a random page in the book to see the structure and quality of the extracted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176  GUIDE  TO  MODERN  COOKERY \n",
      "448— EQQS  EN  COCOTTE  A  LA  SOUBISE \n",
      "Garnish  the  bottom  and  sides  of  the  cocottes  with  a  coating \n",
      "of  thick  Soubise  purde.  Break  the  eggs,  season,  and  poach. \n",
      "When  dishing  up,  surround  the  yolks  with  a  thread  of  melted \n",
      "meat-glaze. \n",
      "449— MOULDED  EGGS \n",
      "These  form  a  very  ornamental  dish,  but  the  time  required \n",
      "to  prepare  them  being  comparatively  long,  poached,  soft-boiled, \n",
      "and  other  kinds  of  eggs  are  generally  preferred  in  their  stead. \n",
      "They  are  made  in  variously  shaped  moulds,  ornamented  accord- \n",
      "ing to  the  nature  of  the  preparation,  and  the  eggs  are  broken \n",
      "into  them  direct,  or  they  may  be  inserted  in  the  form  of \n",
      "scrambled  eggs,  together  with  raw  eggs  poached  in  a  hain- \n",
      "marie. \n",
      "Whatever  be  the  mode  of  preparation,  the  moulds  should \n",
      "always  be  liberally  buttered.  The  usual  time  allowed  for  the \n",
      "poaching  of  the  eggs  in  moulds  is  from  ten  to  twelve  minutes, \n",
      "but  when  withdrawn  from  the  bain-marie  it  is  well  to  let  the \n",
      "moulds  stand  awhile  with  the  view  of  promoting  a  settling  of \n",
      "their  contents,  which  action  facilitates  the  ultimate  turning  out \n",
      "of  the  latter. \n",
      "Empty  the  moulds  on  small  pieces  of  toast  or  tartlets,  and \n",
      "arrange  these  in  a  circle  round  the  dish. \n",
      "450— MOULDED  EGGS  A  LA  CARIGNAN \n",
      "Butter  some  Madeleine-moulds,  shaped  like  elongated  shells, \n",
      "and  garnish  them  with  a  thin  coating  of  chicken-stuffing  or \n",
      "crayfish  butter.  Break  the  eggs  in  the  middle  of  the  forcemeat; \n",
      "season,  place  carefully  in  a  bain-marie,  and  poach,  with  cover \n",
      "on,  in  the  oven,  leaving  a  small  opening  for  the  escape  of  the \n",
      "generated  vapour.  Empty  the  moulds  on  toast  cut  to  the  same \n",
      "shape  as  the  moulds  and  fried  in  butter;  arrange  them  on  the \n",
      "dish,  and  coat  with  a  Chateaubriand  sauce. \n",
      "451— MOULDED  EGGS  A  LA  DUCHESSE \n",
      "Butter  some  baba-moulds;  garnish  the  bottom  of  each  with \n",
      "a  large  slice  of  trufHe;  break  an  egg  into  each,  and  poach  in \n",
      "the  bain-marie.  Turn  out  the  moulds  on  to  little  fluted  galettes \n",
      "made  from  Duchesse  potatoes  and  coloured  in  the  oven  after \n",
      "having  been  gilded. \n",
      "Dish  up  in  the  form  of  a  crown,  and  coat  with  a  thickened \n",
      "veal  gravy. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = pymupdf.open(\"a guide to modern cookery.pdf\")\n",
    "example_page = doc[201]\n",
    "text = example_page.get_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic, the data seems to be well extracted and follow a consistent structure. Recipe titles are in all caps followed by instructions. There are some mistakes due to whatever OCR was originally used but they appear to be minor (e.g. \"EQGS\" instead of \"EGGS\".)\n",
    "\n",
    "Now I'll open the PDF and examine it manually:\n",
    "-pages 1-22 are the preface and table of contents.\n",
    "- The glossary could be useful but is structured differently and not all entries are useful. I'll ignore it for now since most entries are elaborated on later.\n",
    "- Each part appears to have a brief introduction before following the structure seen above. \n",
    "- Given that the page numbers of the book begin at PDF page 27, I'll extract each chapter separately to label their metadata according to the chapter title (e.g. \"Stocks\", \"Sauces\", \"Soups\", etc.) without having to iterate through the entire 1000 page PDF immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the table of contents to get the titles and page numbers for each chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTENTS \n",
      "PART    I \n",
      "FUNDAMENTAL   ELEMENTS \n",
      "CHAPTER  I \n",
      "PAGE \n",
      "FONDS  DE  CUISINE  ........  I \n",
      "CHAPTER  II \n",
      "THE  LEADING  WARM   SAUCES     .....  •  '5 \n",
      "CHAPTER  III \n",
      "THE   SMALL  COMPOUND   SAUCES  ...  .  .  24 \n",
      "CHAPTER  IV \n",
      "COLD  SAUCES  AND  COMPOUND  BUTTERS        .....  48 \n",
      "CHAPTER  V \n",
      "SAVOURY  JELLIES  OR  ASPICS  .  ......  59 \n",
      "CHAPTER  VI \n",
      "THE  COURT-BOUILLONS  AND  THE  MARINADES  .  .  .  -64 \n",
      "CHAPTER  VII \n",
      "\\J/:  ELEMENTARY  PREPARATIONS  .....  70 \n",
      "CHAPTER  VIII \n",
      "THE  VARIOUS  GARNISHES   FOR  SOUPS  .  .  .  .  87 \n",
      "CHAPTER  IX \n",
      "GARNISHING  PREPARATIONS   FOR  RELEVis  AND   ENTR]£eS  .  .  92 \n",
      "CHAPTER  X \n",
      "U^DING  CULINARY  OPERATIONS  .  ....  97 \n",
      "\n",
      "xii  CONTENTS \n",
      "PART   II \n",
      "RECIPES  AND   MODES   OF  PROCEDURE \n",
      "CHAPTER  XI \n",
      "PAGE \n",
      "HORS-D'CEUVRES      .  .  .  .  .  .  .  ,  .137 \n",
      "CHAPTER  XII \n",
      "EGGS  .......  .  .        164 \n",
      "CHAPTER  XIII \n",
      "SOUPS  ..........      197 \n",
      "CHAPTER  XIV \n",
      "FISH  ..........        260 \n",
      "CHAPTER  XV \n",
      "RELEVilS  AND  ENTRIES  OF  BUTCHER'S  MEAT  ....       352 \n",
      "CHAPTER  XVI \n",
      "RELEVES  AND  ENTRIES  OF  POULTRY  AND  GAME    ....       473 \n",
      "CHAPTER  XVII \n",
      "ROASTS  AND  SALADS         ........       605 \n",
      "CHAPTER  XVIII \n",
      "VEGETABLES  AND   FARINACEOUS  PRODUCTS  ....       624 \n",
      "CHAPTER  XIX \n",
      "SAVORIES       ..........       678 \n",
      "CHAPTER  XX \n",
      "ENTREMETS.      (SWEETS)  .  .  .....       687 \n",
      "CHAPTER  XXI \n",
      "ICES   AND  SHERBETS  .....  788 \n",
      "CHAPTER  XXII \n",
      "DRINKS   AND   REFRESHMENTS     .  .  .  .  .  .  .816 \n",
      "CHAPTER  XXIII \n",
      "FRUIT-STEWS  AND  JAMS  ,.,,...       820 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = pymupdf.open(\"a guide to modern cookery.pdf\")\n",
    "toc_pages = [doc[20], doc[21]]\n",
    "toc_page_texts = []\n",
    "\n",
    "for page in toc_pages:\n",
    "    text = page.get_text()\n",
    "    toc_page_texts.append(text)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FONDS  DE  CUISINE  \n",
      "  I \n",
      "THE  LEADING  WARM   SAUCES     \n",
      "  •  '5 \n",
      "THE   SMALL  COMPOUND   SAUCES  \n",
      "  24 \n",
      "COLD  SAUCES  AND  COMPOUND  BUTTERS        \n",
      "  48 \n",
      "SAVOURY  JELLIES  OR  ASPICS  \n",
      "  59 \n",
      "THE  COURT-BOUILLONS  AND  THE  MARINADES  \n",
      "  -64 \n",
      "\\J/:  ELEMENTARY  PREPARATIONS  \n",
      "  70 \n",
      "THE  VARIOUS  GARNISHES   FOR  SOUPS  \n",
      "  87 \n",
      "GARNISHING  PREPARATIONS   FOR  RELEVis  AND   ENTR]£eS  \n",
      "  92 \n",
      "U^DING  CULINARY  OPERATIONS  \n",
      "  97 \n",
      "HORS-D'CEUVRES      \n",
      "137 \n",
      "EGGS  \n",
      "        164 \n",
      "SOUPS  \n",
      "      197 \n",
      "FISH  \n",
      "        260 \n",
      "RELEVilS  AND  ENTRIES  OF  BUTCHER'S  MEAT  \n",
      "       352 \n",
      "RELEVES  AND  ENTRIES  OF  POULTRY  AND  GAME    \n",
      "       473 \n",
      "ROASTS  AND  SALADS         \n",
      "       605 \n",
      "VEGETABLES  AND   FARINACEOUS  PRODUCTS  \n",
      "       624 \n",
      "SAVORIES       \n",
      "       678 \n",
      "ENTREMETS\n",
      "       687 \n",
      "ICES   AND  SHERBETS  \n",
      "  788 \n",
      "DRINKS   AND   REFRESHMENTS     \n",
      "816 \n",
      "FRUIT-STEWS  AND  JAMS  ,\n",
      "       820 \n"
     ]
    }
   ],
   "source": [
    "chapters = {}\n",
    "\n",
    "for text in toc_page_texts:\n",
    "    lines = text.split(\"\\n\")\n",
    "    for i, line in enumerate(lines):\n",
    "        if i > 3:\n",
    "            if i%2 == 1:\n",
    "                # the title is the first words of the line \n",
    "                # followed by some amount of \".\"\n",
    "                # the page number is at the end\n",
    "                split_text = line.split(\".\")\n",
    "                title = split_text[0]\n",
    "                page_num = split_text[-1]\n",
    "                chapters[title] = page_num \n",
    "            \n",
    "for chapter in chapters:\n",
    "    print(chapter)\n",
    "    print(chapters[chapter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These chapters have errors:\n",
    "- FONDS  DE  CUISINE  \n",
    "- THE  LEADING  WARM   SAUCES     \n",
    "- THE  COURT-BOUILLONS  AND  THE  MARINADES  \n",
    "- \\J/:  ELEMENTARY  PREPARATIONS  \n",
    "- GARNISHING  PREPARATIONS   FOR  RELEVis  AND   ENTR]£eS  \n",
    "- U^DING  CULINARY  OPERATIONS  \n",
    "- HORS-D'CEUVRES      \n",
    "- RELEVilS  AND  ENTRIES  OF  BUTCHER'S  MEAT  \n",
    "- RELEVES  AND  ENTRIES  OF  POULTRY  AND  GAME    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters['FONDS  DE  CUISINE  '] = 1\n",
    "chapters['THE  LEADING  WARM   SAUCES     '] = 15\n",
    "chapters['THE  COURT-BOUILLONS  AND  THE  MARINADES  '] = 64\n",
    "correct_titles = [\n",
    "    'THE  ELEMENTARY  PREPARATIONS  ',\n",
    "    'GARNISHING  PREPARATIONS   FOR  RELEVES  AND   ENTREES  ',\n",
    "    'LEADING  CULINARY  OPERATIONS  ',\n",
    "    \"HORS-D'OEUVRES      \",\n",
    "    \"RELEVES  AND  ENTREES  OF  BUTCHER'S  MEAT  \",\n",
    "    \"RELEVES  AND  ENTREES  OF  POULTRY  AND  GAME    \"  \n",
    "]\n",
    "incorrect_titles = [\n",
    "    '\\J/:  ELEMENTARY  PREPARATIONS  ',\n",
    "    'GARNISHING  PREPARATIONS   FOR  RELEVis  AND   ENTR]£eS  ',\n",
    "    'U^DING  CULINARY  OPERATIONS  ',\n",
    "    \"HORS-D'CEUVRES      \",\n",
    "    \"RELEVilS  AND  ENTRIES  OF  BUTCHER'S  MEAT  \",\n",
    "    \"RELEVES  AND  ENTRIES  OF  POULTRY  AND  GAME    \" \n",
    "]\n",
    "for i in range(len(correct_titles)):\n",
    "    chapters[correct_titles[i]] = chapters[incorrect_titles[i]]\n",
    "    del chapters[incorrect_titles[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can disregard the first 3 lines, and there are some minor issues with the text (e.g. \"U^DING\" instead of \"LEADING\"). Looking at the PDF, it seems there are some text marks on the original pages of the book that underwent OCR for the PDF. Since there are only a few mistakes, I'll fix these manually just to move forward. If this problem becomes too hindering I'll find a better method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the fixed titles and update the page numbers accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FONDS  DE  CUISINE  \n",
      "27\n",
      "THE  LEADING  WARM   SAUCES     \n",
      "41\n",
      "THE   SMALL  COMPOUND   SAUCES  \n",
      "50\n",
      "COLD  SAUCES  AND  COMPOUND  BUTTERS        \n",
      "74\n",
      "SAVOURY  JELLIES  OR  ASPICS  \n",
      "85\n",
      "THE  COURT-BOUILLONS  AND  THE  MARINADES  \n",
      "90\n",
      "THE  VARIOUS  GARNISHES   FOR  SOUPS  \n",
      "113\n",
      "EGGS  \n",
      "190\n",
      "SOUPS  \n",
      "223\n",
      "FISH  \n",
      "286\n",
      "ROASTS  AND  SALADS         \n",
      "631\n",
      "VEGETABLES  AND   FARINACEOUS  PRODUCTS  \n",
      "650\n",
      "SAVORIES       \n",
      "704\n",
      "ENTREMETS\n",
      "713\n",
      "ICES   AND  SHERBETS  \n",
      "814\n",
      "DRINKS   AND   REFRESHMENTS     \n",
      "842\n",
      "FRUIT-STEWS  AND  JAMS  ,\n",
      "846\n",
      "THE  ELEMENTARY  PREPARATIONS  \n",
      "96\n",
      "GARNISHING  PREPARATIONS   FOR  RELEVES  AND   ENTREES  \n",
      "118\n",
      "LEADING  CULINARY  OPERATIONS  \n",
      "123\n",
      "HORS-D'OEUVRES      \n",
      "163\n",
      "RELEVES  AND  ENTREES  OF  BUTCHER'S  MEAT  \n",
      "378\n",
      "RELEVES  AND  ENTREES  OF  POULTRY  AND  GAME    \n",
      "499\n"
     ]
    }
   ],
   "source": [
    "for chapter in chapters:\n",
    "    chapters[chapter] = int(chapters[chapter])+26  # 27-1 for zero indexing\n",
    "    print(chapter)\n",
    "    print(chapters[chapter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the recipes from Chapter 1, Fonds de Cuisine. After refining the method, then iterate and extract for every chapter. Will also write each extracted chapter to its own text file for future use to prevent having to run all of these cells in order to pick this up again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_nums = list(chapters.values())\n",
    "chapter_range = [page_nums[0], page_nums[1]]\n",
    "pages = []\n",
    "\n",
    "for i in range(chapter_range[0], chapter_range[1]):\n",
    "    page = doc[i]\n",
    "    pages.append(page)\n",
    "    text = page.get_text()\n",
    "    print(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By briefly examining the single chapter output we see the following pattern for most recipes:\n",
    "- Title: \"3- CHICKEN CONSOMME\"\n",
    "- optionally: \"Quantities\" followed by the final amount and a list of ingredients\n",
    "- Instructions: \"Mode of Procedure\" or \"Preparation\"\n",
    "- Remarks: \"Remarks\"\n",
    "\n",
    "Occassionally there is a book title, page number, chapter title,  etc on its own line. Will remove these from the extracted text before extracting recipes via the patterns noted above.\n",
    "\n",
    "Lines for removal will contain:\n",
    "- \"GUIDE  TO  MODERN  COOKERY\"\n",
    "- Chapter title (e.g. \"FONDS DE CUISINE\")\n",
    "\n",
    "There are occasional typos. To handle the occasional typo, use fuzzy matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing line cleaning to an ouput file for easier viewing\n",
    "page_nums = list(chapters.values())\n",
    "titles = list(chapters.keys())\n",
    "chapter_range = [page_nums[0], page_nums[1]]\n",
    "chapter_out = open(\"extracted chapters/chapter1.txt\",'wb')\n",
    "pages = []\n",
    "\n",
    "target_phrases = [\"GUIDE TO MODERN COOKERY\", titles[0]]\n",
    "\n",
    "for i in range(chapter_range[0], chapter_range[1]):\n",
    "    page = doc[i]\n",
    "    pages.append(page)\n",
    "    text = page.get_text()\n",
    "    lines = text.splitlines()\n",
    "    filtered_lines = [\n",
    "        line for line in lines\n",
    "        if not any(fuzz.partial_ratio(line.strip(), phrase) > 80 for phrase in target_phrases)\n",
    "    ]\n",
    "    chapter_out.write(\"\\n\".join(filtered_lines).encode(\"utf8\") + b\"\\n\")\n",
    "\n",
    "chapter_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that most of the inconsequential lines have been removed, the recipes need to be separated and parsed for relevant information. \n",
    "Following the earlier idenitification of the recipe structure, a possible format for a JSONified recipe could be:\n",
    "{\n",
    "    \"recipe_id\": 1,\n",
    "    \"title\": \"Ordinary or White Consomme\"\n",
    "    \"quantities\": {\n",
    "        \"final_amount\": \"4 quarts\",\n",
    "        \"ingredients\": [\n",
    "            \"3 lbs. of shin of beef\",\n",
    "            \"3 lbs. of lean beef\",\n",
    "            ...\n",
    "        ]\n",
    "    },\n",
    "    \"instructions\": \"Preparation - Put the emeat into a stock-pot...\",\n",
    "    \"remarks\": \"Remarks Relative to...\"\n",
    "}\n",
    "\n",
    "Unfortunately, upon further reading and skipping through the book, many of the chapters have only a title and instructions with ingredients spread throughout. The recipe format will instead have \"id\", \"title\", and \"instructions\".\n",
    "\n",
    "I'll now combine the above cleaning step and the recipe extraction. Later, I may revisit the recipe extraction to add Named Entity Recognition to pull out various ingredients or methods to use as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_nums = list(chapters.values())\n",
    "titles = list(chapters.keys())\n",
    "chapter_range = [page_nums[0], page_nums[1]]\n",
    "all_recipes = {}\n",
    "\n",
    "n = 0\n",
    "for i in range(0, len(page_nums) - 1, 2):\n",
    "    chapter_range = [page_nums[i], page_nums[i+1]]\n",
    "    pages = []\n",
    "    recipes = []\n",
    "\n",
    "    # filtering out the title and chapter title lines\n",
    "    target_phrases = [\"GUIDE TO MODERN COOKERY\", titles[n]]\n",
    "    n += 1\n",
    "    for j in range(chapter_range[0], chapter_range[1]):\n",
    "        page = doc[j]\n",
    "        text = page.get_text()\n",
    "        lines = text.splitlines()\n",
    "        filtered_lines = [\n",
    "            line for line in lines\n",
    "            if not any(fuzz.partial_ratio(line.strip(), phrase) > 80 for phrase in target_phrases)\n",
    "        ]\n",
    "        pages.append(\"\\n\".join(filtered_lines))\n",
    "    chapter_text = \"\\n\".join(pages)\n",
    "\n",
    "    # extracting recipes\n",
    "    # extract number and title\n",
    "    recipe_pattern = re.compile(\n",
    "        r'(?P<header>[A-Za-z0-9]{1,4}—\\s+.+?)(?=\\n[A-Za-z0-9]{1,4}—|\\Z)',\n",
    "    re.DOTALL)  # 1 to 4 character identifiers,the em dash, spaces, look ahead to stop capturing when another identifier is found\n",
    "\n",
    "    for block in recipe_pattern.finditer(chapter_text):\n",
    "        block_text = block.group(0) # extract whole match\n",
    "        current_recipe = {}\n",
    "\n",
    "        # extract title and id\n",
    "        header_patter = re.compile(\n",
    "            r'^(?P<id>[A-Za-z0-9]{1,4})—(?P<title>.*)$',\n",
    "            re.MULTILINE\n",
    "        )\n",
    "        header_match = header_patter.search(block_text)\n",
    "        if header_match:\n",
    "            current_recipe[\"recipe_id\"] = header_match.group(\"id\")\n",
    "            current_title = header_match.group(\"title\").strip()\n",
    "            # extract everything until the next recipe match and add to current_recipe as \"instructions\"\n",
    "            current_instructions = block_text[header_match.end():].strip().replace(\"\\n\",\"\")\n",
    "            \n",
    "            # remove the extra spaces and swap '^' with 'e' \n",
    "            current_title = current_title.replace('^', 'e')\n",
    "            current_instructions = current_instructions.replace('^', 'e')\n",
    "            current_title = re.sub(r'\\s+', ' ', current_title).strip()\n",
    "            current_instructions = re.sub(r'\\s+', ' ', current_instructions).strip()\n",
    "\n",
    "            current_recipe['title'] = current_title\n",
    "            current_recipe['instructions'] = current_instructions\n",
    "        else:\n",
    "            # if no header is found, just store everything as instructions\n",
    "            current_instructions = block_text.strip().replace(\"\\n\", \"\")\n",
    "            current_instructions = current_instructions.replace('^', 'e')\n",
    "            current_instructions = re.sub(r'\\s+', ' ', current_instructions).strip()\n",
    "            current_recipe[\"instructions\"] = current_instructions\n",
    "\n",
    "        # add to list of recipes for this chapter\n",
    "        recipes.append(current_recipe)\n",
    "    \n",
    "    # add list of this chapter's recipes to the dictionary of recipes by chapter\n",
    "    all_recipes[titles[n-1]] = recipes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each chapter of JSONified recipes to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"json_chapters\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for chapter, recipe in all_recipes.items():\n",
    "    filename = f\"{chapter}.json\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    with open(filepath, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(recipes, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "1. Preprocess and clean the extracted recipes further\n",
    "    - Optionally: \n",
    "        - May want to perform Named Entity Recognition (NER) to pull out ingredients or other specific techniques.\n",
    "        - Chunk recipe instructions when they get too long\n",
    "2. Compute embeddings\n",
    "    - Generate embeddings for each text chunk and link it with its associated metadata.\n",
    "    - Ollama: https://ollama.com/blog/embedding-models \n",
    "    - Relevant Reddit Thread: https://www.reddit.com/r/LocalLLaMA/comments/17oyd1r/finding_better_embedding_models/\n",
    "    - Embedding Leaderboard: https://huggingface.co/spaces/mteb/leaderboard\n",
    "    - Will likely use either `bge-large-en-v1.5` or `e5-large-v2` or `mxbai-embed-large-v1`, best for my purpose currently seems to be e5\n",
    "    - \n",
    "3. Index with a Vector db \n",
    "    - FAISS, Pinecone,  Weaviate, or Milvus\n",
    "    - insert each embedding with its metadata\n",
    "    - configure similarity parameters\n",
    "    - Ollama tutorials use ChromaDB\n",
    "4. Integrate with the LLM\n",
    "    - Embed the query with the embed model from earlier, then perform similarity search in the vector db. Use whatever is retrieved as context for the LLM.\n",
    "5. Prototype, Test, and Iterate\n",
    "    - Experiment with the various parameters\n",
    "7. Make a Gradio Frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
