{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of the Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import re\n",
    "from rapidfuzz import fuzz, process\n",
    "import os\n",
    "import json\n",
    "import ollama\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Text from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pymupdf.open(\"a guide to modern cookery.pdf\")\n",
    "chapter_one_pages = [1+26,14+26] # chapter one is pages 1 to 14, page 1 begins at 27, -1 for 0 indexing\n",
    "\n",
    "# read the pages of chapter one\n",
    "pages = []\n",
    "for i in range(chapter_one_pages[0], chapter_one_pages[1]):\n",
    "    page = doc[i]\n",
    "    pages.append(page)\n",
    "\n",
    "# clean the pages by removing unnecessary text\n",
    "cleaned_pages = []\n",
    "target_phrases = [\"GUIDE TO MODERN COOKERY\", \"FONDS  DE  CUISINE\"]  # remove the titles that appear\n",
    "for page in pages:\n",
    "    text = page.get_text()\n",
    "    lines = text.splitlines()\n",
    "    filtered_lines = [\n",
    "            line for line in lines\n",
    "            if not any(fuzz.partial_ratio(line.strip(), phrase) > 80 for phrase in target_phrases)\n",
    "        ]\n",
    "    cleaned_pages.append(\"\\n\".join(filtered_lines))\n",
    "chapter_text = \"\\n\".join(cleaned_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Recipes from the Chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting recipes\n",
    "recipes = []\n",
    "\n",
    "# extract number and title\n",
    "recipe_pattern = re.compile(\n",
    "    r'(?P<header>[A-Za-z0-9]{1,4}—\\s+.+?)(?=\\n[A-Za-z0-9]{1,4}—|\\Z)',\n",
    "re.DOTALL)  # 1 to 4 character identifiers,the em dash, spaces, look ahead to stop capturing when another identifier is found\n",
    "\n",
    "for block in recipe_pattern.finditer(chapter_text):\n",
    "    block_text = block.group(0) # extract whole match\n",
    "    current_recipe = {}\n",
    "\n",
    "    # extract title and id\n",
    "    header_patter = re.compile(\n",
    "        r'^(?P<id>[A-Za-z0-9]{1,4})—(?P<title>.*)$',\n",
    "        re.MULTILINE\n",
    "    )\n",
    "    header_match = header_patter.search(block_text)\n",
    "    if header_match:\n",
    "        current_recipe[\"recipe_id\"] = header_match.group(\"id\")\n",
    "        current_title = header_match.group(\"title\").strip()\n",
    "        # extract everything until the next recipe match and add to current_recipe as \"instructions\"\n",
    "        current_instructions = block_text[header_match.end():].strip().replace(\"\\n\",\"\")\n",
    "        \n",
    "        # remove the extra spaces and swap '^' with 'e' \n",
    "        current_title = current_title.replace('^', 'e')\n",
    "        current_instructions = current_instructions.replace('^', 'e')\n",
    "        current_title = re.sub(r'\\s+', ' ', current_title).strip()\n",
    "        current_instructions = re.sub(r'\\s+', ' ', current_instructions).strip()\n",
    "\n",
    "        current_recipe['title'] = current_title\n",
    "        current_recipe['instructions'] = current_instructions\n",
    "    else:\n",
    "        # if no header is found, just store everything as instructions\n",
    "        current_instructions = block_text.strip().replace(\"\\n\", \"\")\n",
    "        current_instructions = current_instructions.replace('^', 'e')\n",
    "        current_instructions = re.sub(r'\\s+', ' ', current_instructions).strip()\n",
    "        current_recipe[\"instructions\"] = current_instructions\n",
    "\n",
    "    # add to list of recipes for this chapter\n",
    "    recipes.append(current_recipe)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing and Storing Embeddings for Each Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists of documents and ids for each recipe\n",
    "documents = []\n",
    "ids = []\n",
    "for recipe in recipes:\n",
    "    text = f\"Title: {recipe['title']} \\n Instructions: {recipe['instructions']}\"\n",
    "    documents.append(text)\n",
    "    ids.append(recipe['recipe_id'])\n",
    "\n",
    "# get or create the collection for the recipes\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = client.get_or_create_collection(name=\"recipes\")\n",
    "\n",
    "# for each recipe, generate the embedding and store it \n",
    "for recipe_id, recipe in zip(ids, documents):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Embedding recipe: {i+1}.\")\n",
    "    response = ollama.embed(model=\"mxbai-embed-large:latest\", input=recipe)\n",
    "    embeddings = response[\"embeddings\"]\n",
    "    # break\n",
    "    collection.add(\n",
    "        ids=[str(recipe_id)],  # use the recipe ID from the book\n",
    "        embeddings=embeddings[0],\n",
    "        documents=[recipe]\n",
    "        # can add recipe metadata here such as ingredients and the chapter title\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Recipe Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example input\n",
    "input = \"What should I cook with thyme and basil?\"\n",
    "\n",
    "# generate an embedding for the input and retrieve the most relevant doc\n",
    "embedded_input = ollama.embed(\n",
    "  model=\"mxbai-embed-large\",\n",
    "  input=input\n",
    ")\n",
    "\n",
    "# use the embedded input to query for the most similar recipes\n",
    "results = collection.query(\n",
    "  query_embeddings=[embedded_input[\"embeddings\"][0]],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "# format the extracted similar text\n",
    "data = results['documents'][0]\n",
    "formatted_data = \"\\n\\n\".join([f\"Document {i+1}: {doc}\" for i, doc in enumerate(data)])\n",
    "\n",
    "# generate a response combining the prompt and data we retrieved \n",
    "output = ollama.generate(\n",
    "  model=\"llama3\",\n",
    "  prompt=f\"Using these recipes: {formatted_data}. Respond to this prompt using one or some of the techniques contained: {input}\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cookbook-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
